{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import py_vncorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VnCoreNLP model folder /home4/bachpt/text_classification/VnCoreNLP already exists! Please load VnCoreNLP from this folder!\n",
      "2024-01-19 03:08:07 INFO  WordSegmenter:24 - Loading Word Segmentation model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/\"\n",
    "os.environ[\"JVM_PATH\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so\"\n",
    "\n",
    "def load_rdrsegmented():\n",
    "    import py_vncorenlp\n",
    "    py_vncorenlp.download_model(save_dir='/home4/bachpt/text_classification/VnCoreNLP')\n",
    "    rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='/home4/bachpt/text_classification/VnCoreNLP')\n",
    "    return rdrsegmenter\n",
    "\n",
    "def tone_normalize(input):\n",
    "    input = (\n",
    "        input.replace(\"òa\", \"oà\")\n",
    "        .replace(\"óa\", \"oá\")\n",
    "        .replace(\"ỏa\", \"oả\")\n",
    "        .replace(\"õa\", \"oã\")\n",
    "        .replace(\"ọa\", \"oạ\")\n",
    "        .replace(\"òe\", \"oè\")\n",
    "        .replace(\"óe\", \"oé\")\n",
    "        .replace(\"ỏe\", \"oẻ\")\n",
    "        .replace(\"õe\", \"oẽ\")\n",
    "        .replace(\"ọe\", \"oẹ\")\n",
    "        .replace(\"ùy\", \"uỳ\")\n",
    "        .replace(\"úy\", \"uý\")\n",
    "        .replace(\"ủy\", \"uỷ\")\n",
    "        .replace(\"ũy\", \"uỹ\")\n",
    "        .replace(\"ụy\", \"uỵ\")\n",
    "    )\n",
    "    return input\n",
    "\n",
    "def text_preprocessed(text):\n",
    "  text = re.sub(r'[\\\"!@#$%^&*(){}?\\\\.,]', '', text)\n",
    "  text= text.strip().split()\n",
    "  text = [word.lower() for word in text]\n",
    "#   text = [word for word in text if word.isalpha()]\n",
    "  text = \" \".join(text)\n",
    "  return text\n",
    "\n",
    "rdrsegmenter = load_rdrsegmented()\n",
    "def preprocess(text):\n",
    "    text = tone_normalize(text.lower())\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "    text = rdrsegmenter.word_segment(text)\n",
    "    return ' '.join(text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = pd.read_csv('/home4/bachpt/text_classification/mixed_train_lowered_shuffled.csv')\n",
    "input['text'] = input['text'].apply(preprocess)\n",
    "input\n",
    "input.to_csv('/home4/bachpt/text_classification/mixed_train_lowered_shuffled_segmented.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
